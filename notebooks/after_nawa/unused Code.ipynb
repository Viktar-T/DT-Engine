{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4991ece4-bd46-4235-9ef0-05da97f143ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# as additional information during development, \n",
    "    # Only to get_column_names\n",
    "    def get_column_names(self, all_columns = False, engin_parameters = True):  # all_columns=False --- doesn't work yet\n",
    "        if all_columns == False:\n",
    "            self.indices_col = [i for i in range(1, len(self.df.columns) + 1, 2)]\n",
    "            self.names_col = [self.df.columns[i] for i in range(1, len(self.df.columns), 2)]\n",
    "        else:\n",
    "            self.indices_col = [i for i in range(len(self.df.columns))]\n",
    "            self.names_col = [self.df.columns[i] for i in range(len(self.df.columns))]\n",
    "        \n",
    "        self.n_df_columns = pd.DataFrame(np.array([self.indices_col, self.names_col]).T) \n",
    "            \n",
    "        self.nc = 6\n",
    "        self.nr = int(np.ceil(len(self.n_df_columns.index) / self.nc))\n",
    "        self.lst_nr = [i for i in range(self.nr)]\n",
    "        self.col_gen = (s for s in itertools.cycle(('index', 'Parameters')))\n",
    "        self.df_cname = pd.DataFrame(np.zeros(self.nr))\n",
    "        for i in range(self.nc):\n",
    "            self.df_cname.insert(len(self.df_cname.columns), f'{next(self.col_gen)}_{i}', \n",
    "                                 self.n_df_columns.iloc[:self.nr, 0])\n",
    "            self.df_cname.insert(len(self.df_cname.columns), f'{next(self.col_gen)}_{i}', \n",
    "                                 self.n_df_columns.iloc[:self.nr, 1])\n",
    "            if len(self.n_df_columns.index) >= self.nr:\n",
    "                self.n_df_columns.drop(self.lst_nr, inplace=True)\n",
    "                self.n_df_columns.index = [i for i in range(len(self.n_df_columns.index))]\n",
    "        \n",
    "        self.df_cname.drop(0, axis=1, inplace=True)\n",
    "        return self.df_cname \n",
    "    \n",
    "    \n",
    "    def choose_rowes(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8219cc-6cad-4a83-8081-3b3e47ee886e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def filter_fuel(self): remove data outliers --- выбросы ---   quantile(0.01) - quantile(0.99)\n",
    "        self.step = 300\n",
    "        self.indices = []\n",
    "        for i in range(0, len(self.res_filtered.index), self.step):\n",
    "            self.lst_range = [j for j in self.res_filtered.index[i:(i+self.step)]]\n",
    "            self.q_low = self.res_filtered.loc[self.lst_range, 'Zużycie paliwa średnie[g/s]'].quantile(0.01)\n",
    "            self.q_hi  = self.res_filtered.loc[self.lst_range, 'Zużycie paliwa średnie[g/s]'].quantile(0.99)\n",
    "            self.index = self.res_filtered[(self.res_filtered['Zużycie paliwa średnie[g/s]'] >= self.q_low) & \n",
    "                             (self.res_filtered['Zużycie paliwa średnie[g/s]'] <= self.q_hi)].index\n",
    "            self.indices += list(self.index)\n",
    "        self.drop_ind = list(set(self.res_filtered.index) - set(self.indices))\n",
    "        self.res_filtered.fillna(method='ffill', inplace=True)\n",
    "        print(f'len(self.drop_ind) - {len(self.drop_ind)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb86aa74-b5a2-4d97-b712-3619cc0463a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def filter_torque(self, lst):\n",
    "\n",
    "self.indices = []\n",
    "self.gr1 = self.res_filtered.groupby('Torque')  # group by 'Torque'\n",
    "self.dic1 = dict(list(self.gr1))\n",
    "for df in self.dic1.values():\n",
    "    self.q_low = df.loc[:, 'Moment obrotowy[Nm]'].quantile(0.01)\n",
    "    self.q_hi  = df.loc[:, 'Moment obrotowy[Nm]'].quantile(0.99)\n",
    "    self.index = df[(df['Moment obrotowy[Nm]'] >= self.q_low) & \n",
    "                     (df['Moment obrotowy[Nm]'] <= self.q_hi)].index\n",
    "    self.indices += list(self.index)\n",
    "self.drop_ind = list(set(self.res_filtered.index) - set(self.indices))\n",
    "self.res_filtered.drop(self.drop_ind, inplace=True)\n",
    "print(f'len(self.drop_ind) - {len(self.drop_ind)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba5b465-6e77-46df-93aa-3e16c0bd0d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def anal_fuel(min_time_f=500):\n",
    "\n",
    "    lst_div_f = [0.005, 0.01, 0.02, 0.03, 0.04, 0.05, 0.8, 1]\n",
    "    t1.div_f = 2\n",
    "    lst_f = np.arange(0.05, 4, 0.01)\n",
    "    lst_min_time_f = [10, 100, 500, 700, 800, 900, 1000, 1500, 2000]\n",
    "    t1.min_time_f = 2000\n",
    "    \n",
    "    t1.filter_data()\n",
    "    df_f_anal = pd.DataFrame(index=t1.dict_gr_res.keys())\n",
    "    \n",
    "    \n",
    "    ser = pd.Series(dtype='float64')\n",
    "    ser.name = f'div_f={t1.div_f}--min_time_f={t1.min_time_f}'\n",
    "    for k in t1.dict_gr_res:\n",
    "        ser.loc[k] = len(t1.dict_gr_res[k])\n",
    "    frame = [df_f_anal, ser]\n",
    "    df_f_anal = pd.concat(frame, axis=1, join='outer')\n",
    "    \n",
    "    \n",
    "    t1.min_time_f = min_time_f\n",
    "    for div_f in lst_div_f:\n",
    "        t1.div_f = div_f\n",
    "        t1.filter_data()\n",
    "        ser = pd.Series(dtype='float64')\n",
    "        ser.name = div_f\n",
    "        for k in t1.dict_gr_res:\n",
    "            ser.loc[k] = len(t1.dict_gr_res[k])\n",
    "\n",
    "        frame = [df_f_anal, ser]\n",
    "        df_f_anal = pd.concat(frame, axis=1, join='outer')\n",
    "\n",
    "    return df_f_anal\n",
    "        #lst_val.append(len(t1.dict_gr_res[k])\n",
    "    #    print(f'{k} --- {len(t1.dict_gr_res[k])}')\n",
    "\n",
    "#df_f_anal = pd.DataFrame(lst_val, index=t1.dict_gr_res.keys(), columns=lst_min_time_f)\n",
    "#df_f_anal\n",
    "anal_fuel(min_time_f=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f7cd39-3ccf-40ad-8fad-a8e3a4a79c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_fuel(self):\n",
    "        self.res_filtered.drop(self.res_filtered[self.res_filtered['Zużycie paliwa średnie[g/s]'] < 0.5].index, \n",
    "                               inplace=True)\n",
    "        \n",
    "        self.indices = []\n",
    "        for f in self.lst_f:\n",
    "            self.div_min = f - self.div_f\n",
    "            self.div_max = f + self.div_f\n",
    "            self.index = self.res_filtered[(self.res_filtered['Zużycie paliwa średnie[g/s]'] >= self.div_min) & \n",
    "                             (self.res_filtered['Zużycie paliwa średnie[g/s]'] <= self.div_max)].index\n",
    "            if len(self.index) > self.min_time_f:\n",
    "                self.indices += list(self.index)\n",
    "                \n",
    "        self.drop_ind = list(set(self.res_filtered.index) - set(self.indices))\n",
    "        self.res_filtered.drop(self.drop_ind, inplace=True)\n",
    "        \n",
    "        self.dict_all_filtures['def filter_fuel(self):'] = True\n",
    "        self.dict_all_filtures['    5.amount of rowes --- '] = len(self.res_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9042f1-8ec2-487c-aba1-7406eefd560a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#self.max_leaf_nodes = max_leaf_nodes\n",
    "        \n",
    "        self.model_DT = DecisionTreeRegressor(max_leaf_nodes=self.max_leaf_nodes, \n",
    "                                             random_state=0)\n",
    "        self.model_DT.fit(self.train_X, self.train_y)\n",
    "        self.val_predicted_DT = self.model_DT.predict(self.val_X)\n",
    "        self.MAE_DT = mean_absolute_error(self.val_y, self.val_predicted_DT)\n",
    "        \n",
    "        self.dict_param['DecisionTree() - '] = {'max_leaf_nodes': self.max_leaf_nodes,\n",
    "                                                'MAE_DT': round(self.MAE_DT, 4)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc31476-ac82-450a-9868-8d6c26a4724b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_max_leaf_nodes(self):  \n",
    "        self.lst_leaf_nodes = [5, 50, 500, 5000, 50000]\n",
    "        self.lst_MAEs = []\n",
    "        for max_leaf_nodes in self.lst_leaf_nodes:\n",
    "            self.DecisionTree(max_leaf_nodes=max_leaf_nodes)\n",
    "            self.lst_MAEs.append(self.MAE_DT)\n",
    "              \n",
    "        self.dict_nodes_MAEs = dict(zip(self.lst_MAEs, self.lst_leaf_nodes))\n",
    "        self.df_nodes_MAEs = pd.DataFrame([self.lst_leaf_nodes, self.lst_MAEs],\n",
    "                                          index=['max_leaf_nodes', 'MAE']).T\n",
    "        self.leaf_nodes = self.dict_nodes_MAEs[min(self.lst_MAEs)]  # leaf nodes for min MAE\n",
    "        self.max_leaf_nodes = self.leaf_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8680739d-ec1d-4ac0-ae62-a3a7cc8b951b",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def RandomForest(self):    \n",
    "        self.val_predicted_RF = self.model_RF_best.predict(self.val_X)\n",
    "        \n",
    "        self.model_RF.fit(self.train_X, self.train_y)\n",
    "        self.val_predicted_RF = self.model_RF.predict(self.val_X)\n",
    "        self.MAE_RF = mean_absolute_error(self.val_y, self.val_predicted_RF)\n",
    "        self.MSE_RF = mean_squared_error(self.val_y, self.val_predicted_RF)\n",
    "        self.r2_RF = r2_score(self.val_y, self.val_predicted_RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9671d9-99d2-46f8-b41f-9c9b6f8d5424",
   "metadata": {},
   "outputs": [],
   "source": [
    "### we use cros validation - train_test_split goes automaticaly\n",
    "self.train_X, self.val_X, self.train_y, self.val_y = train_test_split(self.X, self.y, \n",
    "                                                                      random_state = 0, \n",
    "                                                                     train_size=0.8, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4b0421-d2fa-4c23-84d3-68e9b0fa7b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' !!!!!  def XGBoost   !!!!!!!'''\n",
    "    def XGBoost(self):\n",
    "        self.model_XGB = XGBRegressor(n_estimators=1000, learning_rate=0.01, n_jobs=5)\n",
    "        self.model_XGB.fit(X_train_transformed, y_train, \n",
    "                           early_stopping_rounds=5, \n",
    "                           eval_set=[(X_val_transformed, y_val)], \n",
    "                           verbose=False)\n",
    "        self.val_predicted_XGB = self.model_XGB.predict(X_val_transformed)\n",
    "        self.MAE_XGB = mean_absolute_error(self.val_y, self.val_predicted_XGB)\n",
    "        \n",
    "        self.dict_MAEs['XGBoost() - '] = self.MAE_XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129b01d2-6e29-4282-b918-87eb547b9a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "self.dict_anlyses = open(f\"dict_anlyses_{self.res_name}.json\", \"w\")\n",
    "json.dump(self.dict_param, self.dict_anlyses)\n",
    "self.dict_anlyses.close()\n",
    "\n",
    "self.dict_anlyses = open(f\"dict_anlyses_{self.res_name}.json\", \"r\")\n",
    "self.output = self.dict_anlyses.read()\n",
    "print(self.output)\n",
    "self.output.close()\n",
    "\n",
    "''' ------------------------------'''\n",
    "self.models_param = open(f\"models_param_{self.res_name}.pkl\", \"wb\")\n",
    "pickle.dump(self.dict_param, self.models_param)\n",
    "self.models_param.close()\n",
    "\n",
    "self.models_param = open(f\"models_param_{self.res_name}.pkl\", \"rb\")\n",
    "self.output = pickle.load(self.models_param)\n",
    "print(self.output)\n",
    "self.models_param.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a628ff-f79d-4f1a-b1d5-457fd616fe22",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = {'tr_ON' : ['raw_data\\\\Zew ch ON _ 2018-12-18.xlsx',\n",
    "                            'raw_data\\\\Zew ch ON _ 2018-12-18_eco.xlsx',\n",
    "                          [4.86, 4.88, 4.55, 4.48, 4.2, 4.03, 3.83, 3.45, 3.17, 3.04], # fuel_means=[]\n",
    "                          'load'],                                                     # charac_type ='load'\n",
    "                 'tr_RME' : ['raw_data\\\\RME zew _ 2018-12-20.xlsx',\n",
    "                            'raw_data\\\\RME zew _ 2018-12-20_eco.xlsx', \n",
    "                            [5.23, 5.12, 4.76, 4.6, 4.46, 4.19, 4, 3.6, 3.4, 3.17], \n",
    "                            'load']\n",
    "                }\n",
    "\n",
    "    # charac_type='load' or 'ex_speed'; rotation=1600,1800,..., 2400-rated  \n",
    "    # fuel_means=[] --- we are choosing means for each mode by hands \n",
    "    def __init__(self, charac_type='load', rotation=2400, fuel_means=[]):  \n",
    "        '''        !!!!!!!!!!!!!!!!!!!!!!      '''\n",
    "        \n",
    "        for key, val in self.raw_data.items():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321f32e8-6ca9-4d44-9c13-7aefd085bc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tables_manipulation:\n",
    "    raw_data = {'tr_ON' : ['raw_data\\\\Zew ch ON _ 2018-12-18.xlsx',\n",
    "                           'raw_data\\\\Zew ch ON _ 2018-12-18_eco.xlsx',\n",
    "                          [4.86, 4.88, 4.55, 4.48, 4.2, 4.03, 3.83, 3.45, 3.17, 3.04], # fuel_means=[]\n",
    "                          'ex_speed'],                                                     # charac_type ='load'\n",
    "                 'tr_RME' : ['raw_data\\\\RME zew _ 2018-12-20.xlsx',\n",
    "                            'raw_data\\\\RME zew _ 2018-12-20_eco.xlsx', \n",
    "                            [5.23, 5.12, 4.76, 4.6, 4.46, 4.19, 4, 3.6, 3.4, 3.17], \n",
    "                            'ex_speed']\n",
    "                }\n",
    "    \n",
    "    \n",
    "    def __init__(self):\n",
    "        self.dic_dfs = {}\n",
    "        self.dic_dfs['tr_ON'] = Table_main(address='raw_data\\\\Zew ch ON _ 2018-12-18.xlsx', \n",
    "                                           address_eco='raw_data\\\\Zew ch ON _ 2018-12-18_eco.xlsx', \n",
    "                                           charac_type=[4.86, 4.88, 4.55, 4.48, 4.2, 4.03, 3.83, 3.45, 3.17, 3.04], \n",
    "                                           fuel_means='ex_speed')\n",
    "\n",
    "        return self.dic_dfs\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "self.dic_dfs['tr_RME'] = Table_main(address='raw_data\\\\RME zew _ 2018-12-20.xlsx', \n",
    "                                           address_eco='raw_data\\\\RME zew _ 2018-12-20_eco.xlsx', \n",
    "                                           charac_type=[5.23, 5.12, 4.76, 4.6, 4.46, 4.19, 4, 3.6, 3.4, 3.17], \n",
    "                                           fuel_means='load')\n",
    "\n",
    "    \n",
    "    def __init__(self):\n",
    "        # dic to save all DataFrames processed by class Table_main DataFrames\n",
    "        self.dic_dfs = {}\n",
    "        for key, val in self.raw_data.items():\n",
    "            self.dic_dfs[key] = Table_main(address=val[0], address_eco=val[1], charac_type=val[2], fuel_means=val[3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0f966e-7cf2-4f46-97e3-b2e926ce1bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "    ''' !!!!!  def XGBoost _ only   !!!!!!!'''\n",
    "    def XGBoost_only(self): \n",
    "        \n",
    "        ### start time\n",
    "        self.datetime_XGB_1 = datetime.now()\n",
    "        self.model_XGB = XGBRegressor(n_estimators=100, learning_rate=0.01, random_state=0)\n",
    "        self.pipeline_XGB = Pipeline(steps=[('model', self.model_XGB)])\n",
    "        self.lst_cross_val_score_XGB_MSE = -1 * cross_val_score(self.pipeline_XGB, self.X, self.y, cv=5, \n",
    "                                                                scoring='neg_root_mean_squared_error')\n",
    "        self.lst_cross_val_score_XGB_r2 = -1 * cross_val_score(self.pipeline_XGB, self.X, self.y, cv=5, \n",
    "                                                               scoring='r2')\n",
    "        self.MSE_XGB = self.lst_cross_val_score_XGB_MSE.mean()\n",
    "        self.r2_XGB = self.lst_cross_val_score_XGB_r2.mean()\n",
    "\n",
    "        ### end time\n",
    "        self.datetime_XGB_2 = datetime.now()\n",
    "        self.datetime_XGB = self.datetime_XGB_2 - self.datetime_XGB_1\n",
    "        '''       \n",
    "        self.permut_imp_XGB = PermutationImportance(self.model_XGB, random_state=1).fit(self.X, self.y)        \n",
    "        self.df_permut_imp_XGB = eli5.formatters.as_dataframe.explain_weights_df(self.permut_imp_XGB, \n",
    "                                                        feature_names = self.df[self.features].columns.tolist())        \n",
    "        '''\n",
    "\n",
    "        self.dict_param['XGB: RMSE_XGB:'] = self.MSE_XGB\n",
    "        self.dict_param['r2: RMSE_XGB:'] = self.r2_XGB\n",
    "        self.dict_param['XGB: Time GridSearchCV worked:'] = self.datetime_XGB\n",
    "        #self.dict_param['XGB: permutation_importance:'] = self.df_permut_imp_XGB\n",
    "        \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
